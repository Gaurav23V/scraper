# Automatically created by: scrapy startproject
#
# For more information about the [deploy] section see:
# https://scrapyd.readthedocs.io/en/latest/deploy.html

[settings]
default = scraper.settings

[deploy]
#url = http://localhost:6800/
project = scraper




        # page_links = soup.find_all("a", class_="page-link")
        # href_value = page_links[0]["href"]
        # next_page = urljoin(self.start_urls[0], href_value)
        # if next_page is not None:
        #     yield response.follow(next_page, self.parse)